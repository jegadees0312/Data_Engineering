{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["o4ZJEyp_3ke_","Ijn5EYipK7Ee","o7zex0POJxg-","fHgMH9oTKYD2","xtBdgXVGTqu3","ih85T5QsKv-E","ebx1UTFj2ys2","l6sDK6xbOSUa","U6VgGR8PXry3"],"authorship_tag":"ABX9TyNYIw6xzJk9mxLbrW3ZsGR+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Spark Setup**"],"metadata":{"id":"o4ZJEyp_3ke_"}},{"cell_type":"code","source":["! pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnxdzGQ6CpAl","executionInfo":{"status":"ok","timestamp":1725449665976,"user_tz":-330,"elapsed":54375,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"28c61232-a86d-4cbc-e4ef-6d9604095138"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=f447e1ce460794723046fbd6afe959f72eb7723244b7d1c4b006d2745b7b8914\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}]},{"cell_type":"markdown","source":["# **Spark Example**"],"metadata":{"id":"Ijn5EYipK7Ee"}},{"cell_type":"code","source":["# creating session\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder \\\n","      .appName(\"PySpark Notebook Example\") \\\n","      .getOrCreate()"],"metadata":{"id":"NQ4ZIezECvHD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["customers = [\n","    (1, \"Ravi\", \"Mumbai\"),\n","    (2, \"Priya\", \"Delhi\"),\n","    (3, \"Vijay\", \"Bangalore\"),\n","    (4, \"Anita\", \"Chennai\"),\n","    (5, \"Raj\", \"Hyderabad\"),\n","]\n","\n","transactions = [\n","    (1, 1, 10000.50),\n","    (2, 2, 20000.75),\n","    (3, 1, 15000.25),\n","    (4, 3, 30000.00),\n","    (5, 2, 40000.50),\n","    (6, 4, 25000.00),\n","    (7, 5, 18000.75),\n","    (8, 1, 5000.00),\n","]\n","\n","customer_col = [\"customer_id\", \"Name\", \"city\"]\n","transaction_col = [\"transaction_id\", \"customer_id\", \"amount\"]\n","\n","customer_df = spark.createDataFrame(customers, schema = customer_col)\n","transaction_df = spark.createDataFrame(transactions, schema = transaction_col)"],"metadata":{"id":"CAnwetxsDHx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Customer DataFrame:\")\n","customer_df.show()\n","\n","print(\"Transaction DataFrame:\")\n","transaction_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrmsMnTIEYdT","executionInfo":{"status":"ok","timestamp":1725336625864,"user_tz":-330,"elapsed":8426,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"c123b493-470b-48c2-be19-b105b79bee19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Customer DataFrame:\n","+-----------+-----+---------+\n","|customer_id| Name|     city|\n","+-----------+-----+---------+\n","|          1| Ravi|   Mumbai|\n","|          2|Priya|    Delhi|\n","|          3|Vijay|Bangalore|\n","|          4|Anita|  Chennai|\n","|          5|  Raj|Hyderabad|\n","+-----------+-----+---------+\n","\n","Transaction DataFrame:\n","+--------------+-----------+--------+\n","|transaction_id|customer_id|  amount|\n","+--------------+-----------+--------+\n","|             1|          1| 10000.5|\n","|             2|          2|20000.75|\n","|             3|          1|15000.25|\n","|             4|          3| 30000.0|\n","|             5|          2| 40000.5|\n","|             6|          4| 25000.0|\n","|             7|          5|18000.75|\n","|             8|          1|  5000.0|\n","+--------------+-----------+--------+\n","\n"]}]},{"cell_type":"code","source":["# Join the DataFrames on CustomerID\n","customer_transactions_df = customer_df.join(transaction_df, on=\"customer_id\")\n","print(\"Customer Transactions DataFrame:\")\n","customer_transactions_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cz1hCwhtJSL8","executionInfo":{"status":"ok","timestamp":1725337921839,"user_tz":-330,"elapsed":4235,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"d0bab9ab-f6e4-4017-e504-b6c561414eaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Customer Transactions DataFrame:\n","+-----------+-----+---------+--------------+--------+\n","|customer_id| Name|     city|transaction_id|  amount|\n","+-----------+-----+---------+--------------+--------+\n","|          1| Ravi|   Mumbai|             1| 10000.5|\n","|          1| Ravi|   Mumbai|             3|15000.25|\n","|          1| Ravi|   Mumbai|             8|  5000.0|\n","|          2|Priya|    Delhi|             2|20000.75|\n","|          2|Priya|    Delhi|             5| 40000.5|\n","|          3|Vijay|Bangalore|             4| 30000.0|\n","|          4|Anita|  Chennai|             6| 25000.0|\n","|          5|  Raj|Hyderabad|             7|18000.75|\n","+-----------+-----+---------+--------------+--------+\n","\n"]}]},{"cell_type":"code","source":["# Calculate the total amount spent by each customer\n","total_spent_df = customer_transactions_df.groupBy (\"Name\").sum(\"Amount\").withColumnRenamed (\"sum(Amount)\", \"TotalSpent\")\n","print(\"Total Amount Spent by Each Customer: \")\n","total_spent_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Np1niFIqJgQR","executionInfo":{"status":"ok","timestamp":1725338025468,"user_tz":-330,"elapsed":3856,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"ed1202b3-1852-4d9a-90f9-c14d23f93007"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Amount Spent by Each Customer: \n","+-----+----------+\n","| Name|TotalSpent|\n","+-----+----------+\n","| Ravi|  30000.75|\n","|Priya|  60001.25|\n","|Vijay|   30000.0|\n","|Anita|   25000.0|\n","|  Raj|  18000.75|\n","+-----+----------+\n","\n"]}]},{"cell_type":"code","source":["# Find customers who have spent more than 30,000\n","big_spenders_df = total_spent_df.filter(col (\"TotalSpent\") > 30000)\n","print(\"Customers Who Spent More Than 30,000:\")\n","big_spenders_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSBiyYzPJjNR","executionInfo":{"status":"ok","timestamp":1725338076654,"user_tz":-330,"elapsed":3335,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"ba3dce1e-e885-492b-fdeb-467b99478b2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Customers Who Spent More Than 30,000:\n","+-----+----------+\n","| Name|TotalSpent|\n","+-----+----------+\n","| Ravi|  30000.75|\n","|Priya|  60001.25|\n","+-----+----------+\n","\n"]}]},{"cell_type":"code","source":["# Count the number of transactions per customer\n","transactions_count_df = customer_transactions_df.groupBy (\"Name\").count().withColumnRenamed (\"count\", \"TransactionCount\")\n","print(\"Number of Transactions Per Customer: \")\n","transactions_count_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_EGD6XXJotS","executionInfo":{"status":"ok","timestamp":1725338141132,"user_tz":-330,"elapsed":2304,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"e47be696-3d47-44c2-db4e-aa3644beee88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Transactions Per Customer: \n","+-----+----------------+\n","| Name|TransactionCount|\n","+-----+----------------+\n","| Ravi|               3|\n","|Priya|               2|\n","|Vijay|               1|\n","|Anita|               1|\n","|  Raj|               1|\n","+-----+----------------+\n","\n"]}]},{"cell_type":"code","source":["# Sort customers by total amount spent in descending order\n","sorted_spenders_df = total_spent_df.orderBy(col (\"TotalSpent\").desc())\n","print (\"Customers Sorted by Total Spent (Descending):\")\n","sorted_spenders_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96doqnOUJrl6","executionInfo":{"status":"ok","timestamp":1725341751709,"user_tz":-330,"elapsed":4140,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"2ebec16c-f427-488b-c1d1-e7f763490a4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Customers Sorted by Total Spent (Descending):\n","+-----+----------+\n","| Name|TotalSpent|\n","+-----+----------+\n","|Priya|  60001.25|\n","| Ravi|  30000.75|\n","|Vijay|   30000.0|\n","|Anita|   25000.0|\n","|  Raj|  18000.75|\n","+-----+----------+\n","\n"]}]},{"cell_type":"markdown","source":["# **Exercise**"],"metadata":{"id":"o7zex0POJxg-"}},{"cell_type":"code","source":["# Exercise: Product Sales Analysis\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder \\\n","    .appName(\"Product Sales Analysis\") \\\n","    .getOrCreate()\n","\n","products = [\n","    (1, \"Laptop\", \"Electronics\", 50000),\n","    (2, \"Smartphone\", \"Electronics\", 30000),\n","    (3, \"Table\", \"Furniture\", 15000),\n","    (4, \"Chair\", \"Furniture\", 5000),\n","    (5, \"Headphones\", \"Electronics\", 2000),\n","]\n","\n","sales = [\n","    (1, 1, 2),\n","    (2, 2, 1),\n","    (3, 3, 3),\n","    (4, 1, 1),\n","    (5, 4, 5),\n","    (6, 2, 2),\n","    (7, 5, 10),\n","    (8, 3, 1),\n","]\n","\n","product_columns = [\"ProductID\", \"ProductName\", \"Category\", \"Price\"]\n","sales_columns = [\"SaleID\", \"ProductID\", \"Quantity\"]\n","\n","product_df = spark.createDataFrame(products, schema=product_columns)\n","sales_df = spark.createDataFrame(sales, schema=sales_columns)\n","\n","print(\"Products DataFrame:\")\n","product_df.show()\n","\n","print(\"Sales DataFrame:\")\n","sales_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXToieFIYe8S","executionInfo":{"status":"ok","timestamp":1725342147264,"user_tz":-330,"elapsed":2349,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"40f3381a-8472-4af8-a9b5-489e2fd7fd66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Products DataFrame:\n","+---------+-----------+-----------+-----+\n","|ProductID|ProductName|   Category|Price|\n","+---------+-----------+-----------+-----+\n","|        1|     Laptop|Electronics|50000|\n","|        2| Smartphone|Electronics|30000|\n","|        3|      Table|  Furniture|15000|\n","|        4|      Chair|  Furniture| 5000|\n","|        5| Headphones|Electronics| 2000|\n","+---------+-----------+-----------+-----+\n","\n","Sales DataFrame:\n","+------+---------+--------+\n","|SaleID|ProductID|Quantity|\n","+------+---------+--------+\n","|     1|        1|       2|\n","|     2|        2|       1|\n","|     3|        3|       3|\n","|     4|        1|       1|\n","|     5|        4|       5|\n","|     6|        2|       2|\n","|     7|        5|      10|\n","|     8|        3|       1|\n","+------+---------+--------+\n","\n"]}]},{"cell_type":"code","source":["# 1.Join the DataFrames:\n","# Join the product_df and sales_df DataFrames on ProductID to create a combined DataFrame with product and sales data.\n","product_sales_df = product_df.join(sales_df, on=\"ProductID\")\n","print(\"product_sales DataFrame:\")\n","product_sales_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMCEbp78ZF2x","executionInfo":{"status":"ok","timestamp":1725342439188,"user_tz":-330,"elapsed":1530,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"05aa52ad-4520-49fa-8ab4-137d97c02751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["product_sales DataFrame:\n","+---------+-----------+-----------+-----+------+--------+\n","|ProductID|ProductName|   Category|Price|SaleID|Quantity|\n","+---------+-----------+-----------+-----+------+--------+\n","|        1|     Laptop|Electronics|50000|     1|       2|\n","|        1|     Laptop|Electronics|50000|     4|       1|\n","|        2| Smartphone|Electronics|30000|     2|       1|\n","|        2| Smartphone|Electronics|30000|     6|       2|\n","|        3|      Table|  Furniture|15000|     3|       3|\n","|        3|      Table|  Furniture|15000|     8|       1|\n","|        4|      Chair|  Furniture| 5000|     5|       5|\n","|        5| Headphones|Electronics| 2000|     7|      10|\n","+---------+-----------+-----------+-----+------+--------+\n","\n"]}]},{"cell_type":"code","source":["# 2.Calculate Total Sales Value:\n","# For each product, calculate the total sales value by multiplying the price by the quantity sold.\n","\n","total_sale_product_df = product_sales_df.withColumn(\"TotalSalesValue\", col(\"Price\") * col(\"Quantity\"))\n","print(\"Total Sales Value DataFrame:\")\n","total_sale_product_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lH0axOmoZMIh","executionInfo":{"status":"ok","timestamp":1725342522006,"user_tz":-330,"elapsed":2658,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"e45aa652-9467-4808-b921-616608c7c671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Sales Value DataFrame:\n","+---------+-----------+-----------+-----+------+--------+---------------+\n","|ProductID|ProductName|   Category|Price|SaleID|Quantity|TotalSalesValue|\n","+---------+-----------+-----------+-----+------+--------+---------------+\n","|        1|     Laptop|Electronics|50000|     1|       2|         100000|\n","|        1|     Laptop|Electronics|50000|     4|       1|          50000|\n","|        2| Smartphone|Electronics|30000|     2|       1|          30000|\n","|        2| Smartphone|Electronics|30000|     6|       2|          60000|\n","|        3|      Table|  Furniture|15000|     3|       3|          45000|\n","|        3|      Table|  Furniture|15000|     8|       1|          15000|\n","|        4|      Chair|  Furniture| 5000|     5|       5|          25000|\n","|        5| Headphones|Electronics| 2000|     7|      10|          20000|\n","+---------+-----------+-----------+-----+------+--------+---------------+\n","\n"]}]},{"cell_type":"code","source":["# 3.Find the Total Sales for Each Product Category:\n","# Group the data by the Category column and calculate the total sales value for each product category.\n","total_sale_by_category_df = total_sale_product_df.groupBy(\"Category\").sum(\"TotalSalesValue\").withColumnRenamed(\"sum(TotalSalesValue)\",\"TotalSales\")\n","print(\"Total Sales for Each Product Category:\")\n","total_sale_by_category_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTmZWtxXZMz4","executionInfo":{"status":"ok","timestamp":1725342639361,"user_tz":-330,"elapsed":2284,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"1ea39e71-082f-4111-e873-081fba89b2b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Sales for Each Product Category:\n","+-----------+----------+\n","|   Category|TotalSales|\n","+-----------+----------+\n","|Electronics|    260000|\n","|  Furniture|     85000|\n","+-----------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 4.Identify the Top-Selling Product:\n","# Find the product that generated the highest total sales value.\n","high_sale_product = total_sale_product_df.groupBy(\"ProductName\").sum(\"TotalSalesValue\").withColumnRenamed(\"sum(TotalSalesValue)\",\"TotalSales\").orderBy(col(\"TotalSales\").desc()).limit(1)\n","print(\"Top-Selling Product:\")\n","high_sale_product.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GbGsebNUZO8R","executionInfo":{"status":"ok","timestamp":1725342840225,"user_tz":-330,"elapsed":2387,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"b66c775a-5d48-4730-9739-67cbaaba1490"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top-Selling Product:\n","+-----------+----------+\n","|ProductName|TotalSales|\n","+-----------+----------+\n","|     Laptop|    150000|\n","+-----------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 5.Sort the Products by Total Sales Value:\n","# Sort the products by total sales value in descending order.\n","high_sale_product = total_sale_product_df.groupBy(\"ProductName\").sum(\"TotalSalesValue\").withColumnRenamed(\"sum(TotalSalesValue)\",\"TotalSales\").orderBy(col(\"TotalSales\").desc())\n","print(\"product's Total sales value\")\n","high_sale_product.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvfvJ4-hZRTK","executionInfo":{"status":"ok","timestamp":1725343527673,"user_tz":-330,"elapsed":1787,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"8296ffa0-a8f8-4b54-ce2a-ec58b47e4870"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["product's Total sales value\n","+-----------+----------+\n","|ProductName|TotalSales|\n","+-----------+----------+\n","|     Laptop|    150000|\n","| Smartphone|     90000|\n","|      Table|     60000|\n","|      Chair|     25000|\n","| Headphones|     20000|\n","+-----------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 6.Count the Number of Sales for Each Product:\n","# Count the number of sales transactions for each product.\n","product_sales_count_df = product_sales_df.groupBy(\"ProductID\").count().withColumnRenamed(\"count\",\"TransactionCount\")\n","print(\"Number of Sales for Each Product:\")\n","product_sales_count_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyhiGO14ZSh4","executionInfo":{"status":"ok","timestamp":1725343185073,"user_tz":-330,"elapsed":1612,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"222dfde9-b0d7-4ae1-cb7f-108843fea519"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Sales for Each Product:\n","+---------+----------------+\n","|ProductID|TransactionCount|\n","+---------+----------------+\n","|        1|               2|\n","|        2|               2|\n","|        3|               2|\n","|        4|               1|\n","|        5|               1|\n","+---------+----------------+\n","\n"]}]},{"cell_type":"code","source":["# 7.Filter the Products with Total Sales Value Greater Than ₹50,000:\n","# Filter out the products that have a total sales value greater than ₹50,000.\n","filtered_high_sale_product = high_sale_product.filter(col(\"TotalSales\") > 50000)\n","print(\"Products with Total Sales Value Greater Than ₹50,000:\")\n","filtered_high_sale_product.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPtRveKyZUCK","executionInfo":{"status":"ok","timestamp":1725353046833,"user_tz":-330,"elapsed":3128,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"5a2a9336-ed0f-4821-d48e-6494d1b525c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Products with Total Sales Value Greater Than ₹50,000:\n","+-----------+----------+\n","|ProductName|TotalSales|\n","+-----------+----------+\n","|     Laptop|    150000|\n","| Smartphone|     90000|\n","|      Table|     60000|\n","+-----------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["#**RDD Transformation** (Resilient Distributed Dataset)"],"metadata":{"id":"fHgMH9oTKYD2"}},{"cell_type":"code","source":["spark = SparkSession.builder \\\n","      .appName(\"RDD Transformation Example\") \\\n","      .getOrCreate()\n","\n","sc = spark.sparkContext\n","print(\"Spark Session Created\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfUZwhjwKjpH","executionInfo":{"status":"ok","timestamp":1725355514977,"user_tz":-330,"elapsed":417,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"7ae623df-2df5-44fb-e9d3-ea09457ff015"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark Session Created\n"]}]},{"cell_type":"code","source":["data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","rdd = sc.parallelize(data)\n","\n","print(\"original RDD:\", rdd.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGfVGyrsMiP4","executionInfo":{"status":"ok","timestamp":1725355613713,"user_tz":-330,"elapsed":425,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"d2359e1f-50eb-4d2b-b7e2-26ff65e7e33e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["original RDD: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"]}]},{"cell_type":"code","source":["rdd2 = rdd.map(lambda x: x * 2)\n","\n","print(\"RDD after transformation (x**2):\", rdd2.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9Uk3mx0NYWn","executionInfo":{"status":"ok","timestamp":1725355694077,"user_tz":-330,"elapsed":437,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"9d898896-4a50-4c24-f5de-a52d59e421bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RDD after transformation (x**2): [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"]}]},{"cell_type":"code","source":["rdd3 = rdd2.filter(lambda x: x % 2 == 0)\n","\n","print(\"RDD after filtering (even):\", rdd3.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZ54-8fHNqc2","executionInfo":{"status":"ok","timestamp":1725355732456,"user_tz":-330,"elapsed":841,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"6ff5faab-7994-425f-bb0b-764b3fca17c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RDD after filtering (even): [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"]}]},{"cell_type":"code","source":["sentence = [\"Hello World\",\"py spark is geat\", \"RDD transformations\"]\n","rdd4 = sc.parallelize(sentence)\n","ScentenceToWords_rdd = rdd4.flatMap(lambda x: x.split(\" \"))\n","\n","print(\"RDD after flatMap transformation:\", ScentenceToWords_rdd.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAq_vcZpN-JO","executionInfo":{"status":"ok","timestamp":1725356076121,"user_tz":-330,"elapsed":853,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"4901001c-045f-4e6b-bbf3-0952fa908bc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RDD after flatMap transformation: ['Hello', 'World', 'py', 'spark', 'is', 'geat', 'RDD', 'transformations']\n"]}]},{"cell_type":"code","source":["# Actions\n","# 1. collect()\n","result = rdd.collect()\n","print(\"Result of collect action:\", result)\n","# 2. count()\n","result = rdd.count()\n","print(\"Result of count action:\", result)\n","# 3. reduce()\n","result = rdd.reduce(lambda x, y: x + y)\n","print(\"Result of reduce action:\", result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXWOmbjeREY5","executionInfo":{"status":"ok","timestamp":1725356820922,"user_tz":-330,"elapsed":1446,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"8dc73208-6ca1-4ad4-d193-b15059817cb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result of collect action: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","Result of count action: 10\n","Result of reduce action: 55\n"]}]},{"cell_type":"markdown","source":["# **RDD Exercise**"],"metadata":{"id":"xtBdgXVGTqu3"}},{"cell_type":"code","source":["# https://codeshare.io/ez3VNJ\n","# Initialize SparkSession\n","spark = SparkSession.builder.appName(\"SalesDataAnalysis\").getOrCreate()"],"metadata":{"id":"1NhcOawgUCP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sales_data = [\n","    (\"ProductA\", 100),\n","    (\"ProductB\", 150),\n","    (\"ProductA\", 200),\n","    (\"ProductC\", 300),\n","    (\"ProductB\", 250),\n","    (\"ProductC\", 100)\n","]\n","\n","# step 1 -> spark context\n","sc = spark.sparkContext\n","\n","# step 2\n","# task 1 -> creating RDD of sales_data and Printing the first few elements of the RDD\n","sales_rdd = sc.parallelize(sales_data)\n","print(sales_rdd.take(3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGPxfK6pULJF","executionInfo":{"status":"ok","timestamp":1725357714090,"user_tz":-330,"elapsed":856,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"955e2a3e-a79e-41c6-9104-c2c0b6b70b3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('ProductA', 100), ('ProductB', 150), ('ProductA', 200)]\n"]}]},{"cell_type":"code","source":["# step 3 -> Grouping and Aggregating Data\n","\n","# taks 2 -> Group data by product name\n","grouped_sales_rdd = sales_rdd.groupByKey()\n","print(\"Grouped data:\")\n","for k,v in grouped_sales_rdd.collect():\n","  print(k,list(v))\n","\n","# taks 3 -> Calculate total sales by product\n","total_sales_by_product = sales_rdd.reduceByKey(lambda x, y: x + y)\n","print(\"Total sales by product:\")\n","print(total_sales_by_product.collect())\n","\n","# taks 4 -> Sort products by total sales\n","sorted_products = total_sales_by_product.sortBy(lambda x: x[1], ascending=False)\n","print(\"Sorted products by total sales:\")\n","print(sorted_products.collect())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CiVPzz9V6EV","executionInfo":{"status":"ok","timestamp":1725360060266,"user_tz":-330,"elapsed":3293,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"5ed0948d-f778-48aa-a8a3-8e5769a3cf83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Grouped data:\n","ProductA [100, 200]\n","ProductB [150, 250]\n","ProductC [300, 100]\n","Total sales by product:\n","[('ProductA', 300), ('ProductB', 400), ('ProductC', 400)]\n","Sorted products by total sales:\n","[('ProductB', 400), ('ProductC', 400), ('ProductA', 300)]\n"]}]},{"cell_type":"code","source":["#step 4 -> Additional transformations\n","\n","# taks 5 -> Filter products with high sales\n","high_sales_products = total_sales_by_product.filter(lambda x: x[1] > 300)\n","print(\"Products with high sales:\")\n","print(high_sales_products.collect())\n","\n","# task 6 -> Combine Regional Sales Data\n","\n","# regional sales data RDD\n","regional_sales_data = [\n","    (\"ProductA\", 50),\n","    (\"ProductC\", 150)\n","]\n","regional_sales_rdd = sc.parallelize(regional_sales_data)\n","\n","# Combining the two RDDs\n","combined_sales_rdd = sales_rdd.union(regional_sales_rdd)\n","\n","# Calculating new total sales\n","new_total_sales_by_product = combined_sales_rdd.reduceByKey(lambda x, y: x + y)\n","print(\"Combined sales data:\")\n","print(new_total_sales_by_product.collect())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6I1gDbTiW_Yt","executionInfo":{"status":"ok","timestamp":1725360519720,"user_tz":-330,"elapsed":3476,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"509a118d-2b1f-427e-c37c-000a3a226526"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Products with high sales:\n","[('ProductB', 400), ('ProductC', 400)]\n","Combined sales data:\n","[('ProductA', 350), ('ProductC', 550), ('ProductB', 400)]\n"]}]},{"cell_type":"code","source":["# step 5 ->  Perform Actions on the RDD\n","\n","# task 7 -> Count the number of distinct products\n","distinct_products_count = sales_rdd.map(lambda x: x[0]).distinct().count()\n","print(\"Count of distinct products:\", distinct_products_count)\n","\n","# task 8 -> Identify the product with maximum sales\n","max_sales = total_sales_by_product.max()[1]\n","max_sales_products = total_sales_by_product.filter(lambda x: x[1] == max_sales)\n","print(\"Products with maximum sales:\", max_sales_products.map(lambda x: x[0]).collect())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HUfb9bI9ZEc0","executionInfo":{"status":"ok","timestamp":1725359547823,"user_tz":-330,"elapsed":2235,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"09992797-2f19-4469-c6f3-2bc1be6df6a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Count of distinct products: 3\n","Products with maximum sales: ['ProductB', 'ProductC']\n"]}]},{"cell_type":"code","source":["# challenge -> Calculate the Average Sales per Product\n","for k,v in grouped_sales_rdd.collect():\n","  print(k,sum(list(v))/len(list(v)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7X-H_BKrdWuY","executionInfo":{"status":"ok","timestamp":1725360214549,"user_tz":-330,"elapsed":444,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"5e14236a-7f22-4fb2-cd1c-363b80ee4d26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ProductA 150.0\n","ProductB 200.0\n","ProductC 200.0\n"]}]},{"cell_type":"markdown","source":["# **PySpark Exercise Sep_4**"],"metadata":{"id":"ih85T5QsKv-E"}},{"cell_type":"code","source":["# https://codeshare.io/w90yOJ\n","\n","spark = SparkSession.builder \\\n","    .appName(\"Employee Data Analysis\") \\\n","    .getOrCreate()"],"metadata":{"id":"b0m7iDAoK3wN","executionInfo":{"status":"ok","timestamp":1725422295358,"user_tz":-330,"elapsed":8295,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Sample employee data\n","data = [\n","    (1, 'Arjun', 'IT', 75000),\n","    (2, 'Vijay', 'Finance', 85000),\n","    (3, 'Shalini', 'IT', 90000),\n","    (4, 'Sneha', 'HR', 50000),\n","    (5, 'Rahul', 'Finance', 60000),\n","    (6, 'Amit', 'IT', 55000)\n","]\n","\n","# Define schema (columns)\n","columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary']\n","\n","# Create DataFrame\n","employee_df = spark.createDataFrame(data, columns)\n","\n","# Show the DataFrame\n","employee_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wIXziLJLsEV","executionInfo":{"status":"ok","timestamp":1725422310398,"user_tz":-330,"elapsed":11561,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"aa7a822c-1424-4f43-c7dd-379bbfffe4e5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|     Shalini|        IT| 90000|\n","|         4|       Sneha|        HR| 50000|\n","|         5|       Rahul|   Finance| 60000|\n","|         6|        Amit|        IT| 55000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# Task 1: Filter Employees by Salary\n","\n","high_salary_employees = employee_df.filter(col(\"Salary\") > 60000)\n","print(\"Employees with salary greater than 60000:\")\n","high_salary_employees.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s02Y0vkBLyBV","executionInfo":{"status":"ok","timestamp":1725422367198,"user_tz":-330,"elapsed":1398,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"43759a35-820a-4179-caf8-e412c36b785c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Employees with salary greater than 60000:\n","+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|     Shalini|        IT| 90000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# Task 2: Calculate the Average Salary by Department\n","\n","avg_salary_by_dept = employee_df.groupBy(\"Department\").avg(\"Salary\").withColumnRenamed(\"avg(Salary)\", \"AvgerageSalary\")\n","print(\"Average salary by department:\")\n","avg_salary_by_dept.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewrKURecMAkl","executionInfo":{"status":"ok","timestamp":1725422551242,"user_tz":-330,"elapsed":1611,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"a74a9cc8-12ef-4648-b5d2-08595f76e494"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Average salary by department:\n","+----------+-----------------+\n","|Department|   AvgerageSalary|\n","+----------+-----------------+\n","|   Finance|          72500.0|\n","|        IT|73333.33333333333|\n","|        HR|          50000.0|\n","+----------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["# Task 3: Sort Employees by Salary (Descending)\n","\n","sorted_by_salary_desc = employee_df.orderBy(col(\"Salary\").desc())\n","print(\"Employees sorted by salary descending:\")\n","sorted_by_salary_desc.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAErqviMMCHV","executionInfo":{"status":"ok","timestamp":1725422582728,"user_tz":-330,"elapsed":831,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"8f2791bf-6460-4d2a-815e-dc2eedb887b5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Employees sorted by salary descending:\n","+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         3|     Shalini|        IT| 90000|\n","|         2|       Vijay|   Finance| 85000|\n","|         1|       Arjun|        IT| 75000|\n","|         5|       Rahul|   Finance| 60000|\n","|         6|        Amit|        IT| 55000|\n","|         4|       Sneha|        HR| 50000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# Task 4: Add a Bonus Column\n","\n","employee_df_with_bonus = employee_df.withColumn(\"Bonus\", col(\"Salary\") * 0.1)\n","print(\"Employees with bonus column:\")\n","employee_df_with_bonus.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rs_xqYgpMDgO","executionInfo":{"status":"ok","timestamp":1725422605391,"user_tz":-330,"elapsed":841,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"2a54938c-5235-4fbe-b166-296dc096bb44"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Employees with bonus column:\n","+----------+------------+----------+------+------+\n","|EmployeeID|EmployeeName|Department|Salary| Bonus|\n","+----------+------------+----------+------+------+\n","|         1|       Arjun|        IT| 75000|7500.0|\n","|         2|       Vijay|   Finance| 85000|8500.0|\n","|         3|     Shalini|        IT| 90000|9000.0|\n","|         4|       Sneha|        HR| 50000|5000.0|\n","|         5|       Rahul|   Finance| 60000|6000.0|\n","|         6|        Amit|        IT| 55000|5500.0|\n","+----------+------------+----------+------+------+\n","\n"]}]},{"cell_type":"markdown","source":["# **Data Handling - NULL Values**"],"metadata":{"id":"ebx1UTFj2ys2"}},{"cell_type":"code","source":["spark = SparkSession.builder \\\n","    .appName(\"Employee Data Handling\") \\\n","    .getOrCreate()\n","\n","# Sample employee data with null values\n","data = [\n","    (1, 'Arjun', 'IT', 75000),\n","    (2, 'Vijay', 'Finance', 85000),\n","    (3, None, 'IT', 90000),\n","    (4, 'Sneha', 'HR', None),\n","    (5, 'Rahul', None, 60000),\n","    (6, 'Amit', 'IT', 55000)\n","]\n","columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary']\n","\n","# Create DataFrame\n","employee_df = spark.createDataFrame(data, columns)\n","\n","# Show the DataFrame\n","employee_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1hk6PdE254l","executionInfo":{"status":"ok","timestamp":1725433876740,"user_tz":-330,"elapsed":21112,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"a73ee78c-1db4-4639-c6c4-931204ec9ce6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|        NULL|        IT| 90000|\n","|         4|       Sneha|        HR|  NULL|\n","|         5|       Rahul|      NULL| 60000|\n","|         6|        Amit|        IT| 55000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# fillna\n","filled_df = employee_df.fillna({'EmployeeName': 'Unknown', 'Department': 'Unknown'})\n","filled_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97k-xn_S3R5G","executionInfo":{"status":"ok","timestamp":1725433924962,"user_tz":-330,"elapsed":1805,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"4ed3195d-4f1b-4889-eb97-0dee10057b33"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|     Unknown|        IT| 90000|\n","|         4|       Sneha|        HR|  NULL|\n","|         5|       Rahul|   Unknown| 60000|\n","|         6|        Amit|        IT| 55000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# drop where salary is NULL\n","dropped_null_salary = employee_df.na.drop(subset=[\"Salary\"])\n","dropped_null_salary.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"je0_cQzp4GWX","executionInfo":{"status":"ok","timestamp":1725433982432,"user_tz":-330,"elapsed":1203,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"63f5a928-956a-47bf-bbb2-6c946b6c83ec"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|        NULL|        IT| 90000|\n","|         5|       Rahul|      NULL| 60000|\n","|         6|        Amit|        IT| 55000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# fill NULL salary with 50000\n","filled_null_salary = employee_df.fillna({'Salary': 50000})\n","filled_null_salary.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pu0SNCvz4VKH","executionInfo":{"status":"ok","timestamp":1725434051940,"user_tz":-330,"elapsed":2002,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"efcdd9be-144a-4234-8fb4-6f1fd133ca8c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|        NULL|        IT| 90000|\n","|         4|       Sneha|        HR| 50000|\n","|         5|       Rahul|      NULL| 60000|\n","|         6|        Amit|        IT| 55000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# check for NULL values in entire table\n","null_check = employee_df.select([col(column).isNull().alias(column) for column in employee_df.columns])\n","null_check.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8ouXeb14otX","executionInfo":{"status":"ok","timestamp":1725434165421,"user_tz":-330,"elapsed":1371,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"c7e41028-6df6-42ba-83ba-9a2902b23acc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|     false|       false|     false| false|\n","|     false|       false|     false| false|\n","|     false|        true|     false| false|\n","|     false|       false|     false|  true|\n","|     false|       false|      true| false|\n","|     false|       false|     false| false|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"code","source":["# replace all NULL values with 'N/A'\n","replaced_df = employee_df.na.fill('N/A')\n","replaced_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVQZygiz5Bk-","executionInfo":{"status":"ok","timestamp":1725434281766,"user_tz":-330,"elapsed":1786,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"a7096058-2fa3-4993-cb09-75e09c53d9ab"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+\n","|EmployeeID|EmployeeName|Department|Salary|\n","+----------+------------+----------+------+\n","|         1|       Arjun|        IT| 75000|\n","|         2|       Vijay|   Finance| 85000|\n","|         3|         N/A|        IT| 90000|\n","|         4|       Sneha|        HR|  NULL|\n","|         5|       Rahul|       N/A| 60000|\n","|         6|        Amit|        IT| 55000|\n","+----------+------------+----------+------+\n","\n"]}]},{"cell_type":"markdown","source":["# **Window and Dates** - Advanced DataFrame operations"],"metadata":{"id":"l6sDK6xbOSUa"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","\n","spark = SparkSession.builder \\\n","    .appName(\"Advanced DataFrame operations\") \\\n","    .getOrCreate()\n","\n","data1 = [\n","    (1, 'Arjun', 'IT', 75000, '2022-01-15'),\n","    (2, 'Vijay', 'Finance', 85000, '2022-03-12'),\n","    (3, 'Shalini', 'IT', 90000, '2021-06-10'),\n","    (4, 'Sneha', 'IT', 90000, '2022-02-28'),\n","]\n","\n","data2 = [\n","    (5, 'Vikram', 'HR', 50000, '2022-05-01'),\n","    (6, 'Amit', 'Finance', 60000, '2022-04-05'),\n","    (7, 'Priya', 'IT', 55000, '2022-03-15'),\n","    (8, 'Rahul', 'Finance', 70000, '2022-02-20'),\n","    (9, 'Anjali', 'HR', 65000, '2022-01-25'),\n","]\n","\n","columns = ['EmployeeID', 'EmployeeName', 'Department', 'Salary', 'JoiningDate']\n","\n","employee_df1 = spark.createDataFrame(data1, columns)\n","employee_df2 = spark.createDataFrame(data2, columns)\n","\n","employee_df1.show()\n","employee_df2.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaFYIPnsOtMp","executionInfo":{"status":"ok","timestamp":1725440700112,"user_tz":-330,"elapsed":3406,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"4cf1e3e3-a885-4aa4-bc92-c63128e28b56"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|\n","+----------+------------+----------+------+-----------+\n","\n","+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         5|      Vikram|        HR| 50000| 2022-05-01|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|\n","|         7|       Priya|        IT| 55000| 2022-03-15|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["# union 2 dataframes\n","\n","# remove duplicates\n","union_df = employee_df1.union(employee_df2).dropDuplicates()\n","\n","# include duplicates\n","union_df = employee_df1.union(employee_df2)\n","union_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYLrLhj4R8MI","executionInfo":{"status":"ok","timestamp":1725440845524,"user_tz":-330,"elapsed":1837,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"4ed7b557-7bcd-4671-d0be-563f0145af99"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|\n","|         7|       Priya|        IT| 55000| 2022-03-15|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.window import Window\n","from pyspark.sql.functions import rank\n","\n","# window specification to rank employees by salary witin each department\n","window_spec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n","\n","# add a new column 'Rank' to the DataFrame\n","ranked_df = union_df.withColumn(\"Rank\", rank().over(window_spec))\n","ranked_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VsImiahSN2Q","executionInfo":{"status":"ok","timestamp":1725441053564,"user_tz":-330,"elapsed":3001,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"b8457865-5239-4667-dc94-ed9409af2cde"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+----+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|Rank|\n","+----------+------------+----------+------+-----------+----+\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|   1|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|   2|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|   3|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|   1|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|   2|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|   1|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|   1|\n","|         1|       Arjun|        IT| 75000| 2022-01-15|   3|\n","|         7|       Priya|        IT| 55000| 2022-03-15|   4|\n","+----------+------------+----------+------+-----------+----+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.sql.functions import sum\n","\n","# window specification for cumulative sum of salaries within each departmrnt\n","window_spec_sum = Window.partitionBy(\"Department\").orderBy(\"JoiningDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n","\n","# add a new column 'CumulativeSalary' to the DataFrame\n","cumulative_salary_df = union_df.withColumn(\"CumulativeSalary\", sum(\"Salary\").over(window_spec_sum))\n","cumulative_salary_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOiD66vJTX3S","executionInfo":{"status":"ok","timestamp":1725441357263,"user_tz":-330,"elapsed":1992,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"2aa99b95-aa23-4f65-e9ac-b212d8df4ac6"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+----------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|CumulativeSalary|\n","+----------+------------+----------+------+-----------+----------------+\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|           70000|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|          155000|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|          215000|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|           65000|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|          115000|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|           90000|\n","|         1|       Arjun|        IT| 75000| 2022-01-15|          165000|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|          255000|\n","|         7|       Priya|        IT| 55000| 2022-03-15|          310000|\n","+----------+------------+----------+------+-----------+----------------+\n","\n"]}]},{"cell_type":"code","source":["# joining date from String -> Date type\n","\n","date_converted_df = union_df.withColumn(\"JoiningDate\", F.to_date(col(\"JoiningDate\"), \"yyyy-MM-dd\"))\n","date_converted_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2BS18VXUycC","executionInfo":{"status":"ok","timestamp":1725441571793,"user_tz":-330,"elapsed":2029,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"f5acbfa7-19ca-431e-ef26-cbf375302d63"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|\n","+----------+------------+----------+------+-----------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|\n","|         7|       Priya|        IT| 55000| 2022-03-15|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|\n","+----------+------------+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["# number of years since joining\n","experienced_df = date_converted_df.withColumn(\"YearsOfExperience\", F.round(F.datediff(F.current_date(), col(\"JoiningDate\")) / 365,2))\n","experienced_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xk_32lvNVR5f","executionInfo":{"status":"ok","timestamp":1725441806912,"user_tz":-330,"elapsed":1303,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"167eea17-12ce-4e43-f5c8-cd31ad40e154"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+-----------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|YearsOfExperience|\n","+----------+------------+----------+------+-----------+-----------------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|             2.64|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|             2.48|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|             3.24|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|             2.52|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|             2.35|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|             2.42|\n","|         7|       Priya|        IT| 55000| 2022-03-15|             2.48|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|             2.54|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|             2.61|\n","+----------+------------+----------+------+-----------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["# adding column for next evaluation date\n","eval_date_df = date_converted_df.withColumn(\"NextEvaluationDate\", F.date_add(col(\"JoiningDate\"), 365))\n","eval_date_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-xk0zasWK_v","executionInfo":{"status":"ok","timestamp":1725441902845,"user_tz":-330,"elapsed":2746,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"19ef3242-5c1a-42ef-b36f-9dfa21847c3c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+------------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|NextEvaluationDate|\n","+----------+------------+----------+------+-----------+------------------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|        2023-01-15|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|        2023-03-12|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|        2022-06-10|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|        2023-02-28|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|        2023-05-01|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|        2023-04-05|\n","|         7|       Priya|        IT| 55000| 2022-03-15|        2023-03-15|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|        2023-02-20|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|        2023-01-25|\n","+----------+------------+----------+------+-----------+------------------+\n","\n"]}]},{"cell_type":"code","source":["# average salary per department\n","avg_salary_df = date_converted_df.groupBy(\"Department\").agg(F.avg(\"Salary\").alias(\"AverageSalary\"))\n","avg_salary_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7gaLcX6WkvQ","executionInfo":{"status":"ok","timestamp":1725441978252,"user_tz":-330,"elapsed":4282,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"3a1b98f9-325f-49f6-abf8-1124d21f8f22"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-----------------+\n","|Department|    AverageSalary|\n","+----------+-----------------+\n","|   Finance|71666.66666666667|\n","|        IT|          77500.0|\n","|        HR|          57500.0|\n","+----------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["# total number of employees\n","total_employees_df = date_converted_df.agg(F.count(\"EmployeeID\").alias(\"TotalEmployees\"))\n","total_employees_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GX7KeRiW18X","executionInfo":{"status":"ok","timestamp":1725442061906,"user_tz":-330,"elapsed":2227,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"44063ec2-2518-42bb-ea43-8abe54328d3d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------+\n","|TotalEmployees|\n","+--------------+\n","|             9|\n","+--------------+\n","\n"]}]},{"cell_type":"code","source":["# Employees name to upper\n","upper_name_df = date_converted_df.withColumn(\"EmployeeNameUpper\", F.upper(col(\"EmployeeName\")))\n","upper_name_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aw7jQRyOXIVn","executionInfo":{"status":"ok","timestamp":1725442137686,"user_tz":-330,"elapsed":2047,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"30d9f889-9bf2-4687-dd0d-f05f1458502f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------------+----------+------+-----------+-----------------+\n","|EmployeeID|EmployeeName|Department|Salary|JoiningDate|EmployeeNameUpper|\n","+----------+------------+----------+------+-----------+-----------------+\n","|         1|       Arjun|        IT| 75000| 2022-01-15|            ARJUN|\n","|         2|       Vijay|   Finance| 85000| 2022-03-12|            VIJAY|\n","|         3|     Shalini|        IT| 90000| 2021-06-10|          SHALINI|\n","|         4|       Sneha|        IT| 90000| 2022-02-28|            SNEHA|\n","|         5|      Vikram|        HR| 50000| 2022-05-01|           VIKRAM|\n","|         6|        Amit|   Finance| 60000| 2022-04-05|             AMIT|\n","|         7|       Priya|        IT| 55000| 2022-03-15|            PRIYA|\n","|         8|       Rahul|   Finance| 70000| 2022-02-20|            RAHUL|\n","|         9|      Anjali|        HR| 65000| 2022-01-25|           ANJALI|\n","+----------+------------+----------+------+-----------+-----------------+\n","\n"]}]},{"cell_type":"markdown","source":["# **Advance DataFrame Exercise 4th Sep**"],"metadata":{"id":"U6VgGR8PXry3"}},{"cell_type":"code","source":["# https://codeshare.io/BdPVKx\n","\n","# Data Setup:\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","\n","# Initialize a Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"Advanced DataFrame Operations - Different Dataset\") \\\n","    .getOrCreate()\n","\n","# Create two sample DataFrames for Product Sales\n","data1 = [\n","    (1, 'Product A', 'Electronics', 1200, '2022-05-10'),\n","    (2, 'Product B', 'Clothing', 500, '2022-07-15'),\n","    (3, 'Product C', 'Electronics', 1800, '2021-11-05')\n","]\n","\n","data2 = [\n","    (4, 'Product D', 'Furniture', 3000, '2022-03-25'),\n","    (5, 'Product E', 'Clothing', 800, '2022-09-12'),\n","    (6, 'Product F', 'Electronics', 1500, '2021-10-19')\n","]\n","\n","# Define schema (columns)\n","columns = ['ProductID', 'ProductName', 'Category', 'Price', 'SaleDate']\n","\n","# Create DataFrames\n","sales_df1 = spark.createDataFrame(data1, columns)\n","sales_df2 = spark.createDataFrame(data2, columns)\n","\n","# Show the DataFrames\n","sales_df1.show()\n","sales_df2.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQJIdcmSzFdx","executionInfo":{"status":"ok","timestamp":1725449722903,"user_tz":-330,"elapsed":8865,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"c28b124c-78e4-409d-b205-134a8910c640"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+-----------+-----------+-----+----------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|\n","+---------+-----------+-----------+-----+----------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|\n","|        2|  Product B|   Clothing|  500|2022-07-15|\n","|        3|  Product C|Electronics| 1800|2021-11-05|\n","+---------+-----------+-----------+-----+----------+\n","\n","+---------+-----------+-----------+-----+----------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|\n","+---------+-----------+-----------+-----+----------+\n","|        4|  Product D|  Furniture| 3000|2022-03-25|\n","|        5|  Product E|   Clothing|  800|2022-09-12|\n","|        6|  Product F|Electronics| 1500|2021-10-19|\n","+---------+-----------+-----------+-----+----------+\n","\n"]}]},{"cell_type":"code","source":["# 1.Union of DataFrames (removing duplicates):\n","# Combine the two DataFrames (`sales_df1` and `sales_df2`) using `union` and remove any duplicate rows.\n","\n","combined_df_noDuplicates = sales_df1.union(sales_df2).dropDuplicates()\n","print(\"Combined DataFrame (removing duplicates):\")\n","combined_df_noDuplicates.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoPDbRw-zlls","executionInfo":{"status":"ok","timestamp":1725449883290,"user_tz":-330,"elapsed":3618,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"8909111d-67e8-4acd-c865-3793c0ca55bb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined DataFrame (removing duplicates):\n","+---------+-----------+-----------+-----+----------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|\n","+---------+-----------+-----------+-----+----------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|\n","|        2|  Product B|   Clothing|  500|2022-07-15|\n","|        3|  Product C|Electronics| 1800|2021-11-05|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|\n","|        6|  Product F|Electronics| 1500|2021-10-19|\n","|        5|  Product E|   Clothing|  800|2022-09-12|\n","+---------+-----------+-----------+-----+----------+\n","\n"]}]},{"cell_type":"code","source":["# 2.Union of DataFrames (including duplicates):\n","# Combine both DataFrames using `unionAll` (replaced by `union`) and include duplicate rows.\n","\n","combined_df_Duplicates = sales_df1.unionAll(sales_df2)\n","print(\"Combined DataFrame (including duplicates):\")\n","combined_df_Duplicates.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QWn5tQszuUa","executionInfo":{"status":"ok","timestamp":1725449907885,"user_tz":-330,"elapsed":1687,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"6ce484b7-8ab1-4cc0-ef1b-3cf48cb61b0c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined DataFrame (including duplicates):\n","+---------+-----------+-----------+-----+----------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|\n","+---------+-----------+-----------+-----+----------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|\n","|        2|  Product B|   Clothing|  500|2022-07-15|\n","|        3|  Product C|Electronics| 1800|2021-11-05|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|\n","|        5|  Product E|   Clothing|  800|2022-09-12|\n","|        6|  Product F|Electronics| 1500|2021-10-19|\n","+---------+-----------+-----------+-----+----------+\n","\n"]}]},{"cell_type":"code","source":["# 3.Rank products by price within their category:\n","# Use window functions to rank the products in each category by price in descending order.\n","\n","window1 = Window.partitionBy(\"Category\").orderBy(col(\"Price\").desc())\n","ranked_df = combined_df_noDuplicates.withColumn(\"Rank\", F.rank().over(window1))\n","print(\"Ranked products by price within their category:\")\n","ranked_df.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVUlqXyfzqxr","executionInfo":{"status":"ok","timestamp":1725449988598,"user_tz":-330,"elapsed":3294,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"dbcb72d0-658a-4f67-834b-b51499cc43f7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Ranked products by price within their category:\n","+---------+-----------+-----------+-----+----------+----+\n","|ProductID|ProductName|   Category|Price|  SaleDate|Rank|\n","+---------+-----------+-----------+-----+----------+----+\n","|        5|  Product E|   Clothing|  800|2022-09-12|   1|\n","|        2|  Product B|   Clothing|  500|2022-07-15|   2|\n","|        3|  Product C|Electronics| 1800|2021-11-05|   1|\n","|        6|  Product F|Electronics| 1500|2021-10-19|   2|\n","|        1|  Product A|Electronics| 1200|2022-05-10|   3|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|   1|\n","+---------+-----------+-----------+-----+----------+----+\n","\n"]}]},{"cell_type":"code","source":["# 4.Calculate cumulative price per category:\n","# Use window functions to calculate the cumulative price of products within each category.\n","\n","window2 = Window.partitionBy(\"Category\").orderBy(\"SaleDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n","cumulative_price_df = combined_df_noDuplicates.withColumn(\"CumulativePrice\", F.sum(\"Price\").over(window2))\n","print(\"Cumulative price per category:\")\n","cumulative_price_df.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bogzrIeazvU0","executionInfo":{"status":"ok","timestamp":1725450293466,"user_tz":-330,"elapsed":2530,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"a24c1bdb-3c58-4b8b-b78d-d44206926ab0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Cumulative price per category:\n","+---------+-----------+-----------+-----+----------+---------------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|CumulativePrice|\n","+---------+-----------+-----------+-----+----------+---------------+\n","|        2|  Product B|   Clothing|  500|2022-07-15|            500|\n","|        5|  Product E|   Clothing|  800|2022-09-12|           1300|\n","|        6|  Product F|Electronics| 1500|2021-10-19|           1500|\n","|        3|  Product C|Electronics| 1800|2021-11-05|           3300|\n","|        1|  Product A|Electronics| 1200|2022-05-10|           4500|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|           3000|\n","+---------+-----------+-----------+-----+----------+---------------+\n","\n"]}]},{"cell_type":"code","source":["# 5.Convert `SaleDate` from string to date type:\n","# Convert the `SaleDate` column from string format to a PySpark date type.\n","\n","date_converted_df = combined_df_noDuplicates.withColumn(\"SaleDate\", F.to_date(col(\"SaleDate\"), \"yyyy-MM-dd\"))\n","print(\"DataFrame with SaleDate in date type:\")\n","date_converted_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gWu1Dacezy5K","executionInfo":{"status":"ok","timestamp":1725450366045,"user_tz":-330,"elapsed":1994,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"c9c7b569-3028-497b-fad3-261da76b2a34"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame with SaleDate in date type:\n","+---------+-----------+-----------+-----+----------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|\n","+---------+-----------+-----------+-----+----------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|\n","|        2|  Product B|   Clothing|  500|2022-07-15|\n","|        3|  Product C|Electronics| 1800|2021-11-05|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|\n","|        6|  Product F|Electronics| 1500|2021-10-19|\n","|        5|  Product E|   Clothing|  800|2022-09-12|\n","+---------+-----------+-----------+-----+----------+\n","\n"]}]},{"cell_type":"code","source":["# 6.Calculate the number of days since each sales:\n","# Calculate the number of days since each product was sold using the current date.\n","\n","days_since_sale_df = date_converted_df.withColumn(\"DaysSinceSale\", F.datediff(F.current_date(), col(\"SaleDate\")))\n","print(\"DataFrame with DaysSinceSale column:\")\n","days_since_sale_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGkpsN6DzyxR","executionInfo":{"status":"ok","timestamp":1725450438084,"user_tz":-330,"elapsed":2010,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"9bfdbd66-8bdd-4df2-963b-4b2c85403e29"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame with DaysSinceSale column:\n","+---------+-----------+-----------+-----+----------+-------------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|DaysSinceSale|\n","+---------+-----------+-----------+-----+----------+-------------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|          848|\n","|        2|  Product B|   Clothing|  500|2022-07-15|          782|\n","|        3|  Product C|Electronics| 1800|2021-11-05|         1034|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|          894|\n","|        6|  Product F|Electronics| 1500|2021-10-19|         1051|\n","|        5|  Product E|   Clothing|  800|2022-09-12|          723|\n","+---------+-----------+-----------+-----+----------+-------------+\n","\n"]}]},{"cell_type":"code","source":["# 7.Add a column for the next sale deadline:\n","# Add a new column `NextSaleDeadline`, which should be 30 days after the `SaleDate`.\n","\n","next_sale_deadline_df = date_converted_df.withColumn(\"NextSaleDeadline\", F.date_add(col(\"SaleDate\"), 30))\n","print(\"DataFrame with NextSaleDeadline column:\")\n","next_sale_deadline_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pi4lY0EKzya0","executionInfo":{"status":"ok","timestamp":1725450479344,"user_tz":-330,"elapsed":1707,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"8b675d14-e5cd-4a41-9d9f-cc684b5d8058"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame with NextSaleDeadline column:\n","+---------+-----------+-----------+-----+----------+----------------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|NextSaleDeadline|\n","+---------+-----------+-----------+-----+----------+----------------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|      2022-06-09|\n","|        2|  Product B|   Clothing|  500|2022-07-15|      2022-08-14|\n","|        3|  Product C|Electronics| 1800|2021-11-05|      2021-12-05|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|      2022-04-24|\n","|        6|  Product F|Electronics| 1500|2021-10-19|      2021-11-18|\n","|        5|  Product E|   Clothing|  800|2022-09-12|      2022-10-12|\n","+---------+-----------+-----------+-----+----------+----------------+\n","\n"]}]},{"cell_type":"code","source":["# 8.Calculate total revenue and average price per category:\n","# Find the total revenue (sum of prices) and the average price per category.\n","\n","total_revenue_df = date_converted_df.groupBy(\"Category\").agg(F.sum(\"Price\").alias(\"TotalRevenue\"), F.avg(\"Price\").alias(\"AveragePrice\"))\n","print(\"Total revenue and average price per category:\")\n","total_revenue_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qivv1O4Gz21K","executionInfo":{"status":"ok","timestamp":1725450570186,"user_tz":-330,"elapsed":2094,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"8194f97a-29fb-40cf-aec4-05d5de952a58"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Total revenue and average price per category:\n","+-----------+------------+------------+\n","|   Category|TotalRevenue|AveragePrice|\n","+-----------+------------+------------+\n","|Electronics|        4500|      1500.0|\n","|   Clothing|        1300|       650.0|\n","|  Furniture|        3000|      3000.0|\n","+-----------+------------+------------+\n","\n"]}]},{"cell_type":"code","source":["# 9.Convert all product names to lowercase:\n","# Create a new column with all product names in lowercase.\n","\n","lowercase_names_df = combined_df_noDuplicates.withColumn(\"ProductNameLower\", F.lower(col(\"ProductName\")))\n","print(\"DataFrame with ProductName in lowercase:\")\n","lowercase_names_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SBNl8VUz2t5","executionInfo":{"status":"ok","timestamp":1725450590234,"user_tz":-330,"elapsed":2816,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"fed79d3f-641f-4d10-eb3e-4a1b96beda9b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame with ProductName in lowercase:\n","+---------+-----------+-----------+-----+----------+----------------+\n","|ProductID|ProductName|   Category|Price|  SaleDate|ProductNameLower|\n","+---------+-----------+-----------+-----+----------+----------------+\n","|        1|  Product A|Electronics| 1200|2022-05-10|       product a|\n","|        2|  Product B|   Clothing|  500|2022-07-15|       product b|\n","|        3|  Product C|Electronics| 1800|2021-11-05|       product c|\n","|        4|  Product D|  Furniture| 3000|2022-03-25|       product d|\n","|        6|  Product F|Electronics| 1500|2021-10-19|       product f|\n","|        5|  Product E|   Clothing|  800|2022-09-12|       product e|\n","+---------+-----------+-----------+-----+----------+----------------+\n","\n"]}]},{"cell_type":"markdown","source":["# **Topic**"],"metadata":{"id":"-cvm84j0X1MX"}},{"cell_type":"markdown","source":["# **Topic**"],"metadata":{"id":"4SlLpVQqX5Lo"}},{"cell_type":"markdown","source":["# **Topic**"],"metadata":{"id":"aewkii5LX6Cf"}},{"cell_type":"markdown","source":["# **Topic**"],"metadata":{"id":"vPSlwo56X62e"}}]}